from sklearn.metrics import f1_score, accuracy_score, roc_auc_score
from rich.console import Console
from rich.table import Table
import numpy as np

def print_metrics_table(results: dict):
    console = Console()

    # æ‰¾å‡º F1 æœ€ä¼˜æ¨¡å‹
    best_model = max(results, key=lambda k: results[k]["F1"])

    table = Table(
        title="ğŸ“Š Model Evaluation Results",
        show_header=True,
        header_style="bold cyan"
    )

    table.add_column("Model", style="bold")
    table.add_column("F1", justify="right")
    table.add_column("Accuracy", justify="right")
    table.add_column("AUC", justify="right")
    table.add_column("Threshold", justify="center")

    for model_name, metrics in results.items():
        threshold = metrics.get("BestThreshold", 0.5)

        table.add_row(
            model_name,
            f"{metrics['F1']:.4f}",
            f"{metrics['Accuracy']:.4f}",
            f"{metrics['AUC']:.4f}",
            f"{threshold:.2f}"
        )

    console.print(table)

    # è¡¨æ ¼å¤–å•ç‹¬å¼ºè°ƒ Best F1
    console.print(
        f"\nâœ… Best model based on F1-score: "
        f"[bold green]{best_model}[/bold green] "
        f"(F1 = {results[best_model]['F1']:.4f}, "
        f"threshold = {results[best_model]['BestThreshold']:.2f})"
    )

def find_best_threshold(model, X_valid, y_valid):
    """
    åœ¨éªŒè¯é›†ä¸Šæœç´¢ä½¿ F1-score æœ€å¤§çš„åˆ†ç±»é˜ˆå€¼
    """
    y_proba = model.predict_proba(X_valid)[:, 1]
    thresholds = np.linspace(0.1, 0.9, 81)

    best_f1, best_t = 0.0, 0.5
    for t in thresholds:
        f1 = f1_score(y_valid, (y_proba >= t).astype(int))
        if f1 > best_f1:
            best_f1, best_t = f1, t

    return best_t, best_f1

def evaluate_model(model, X, y, threshold=0.5):
    y_proba = model.predict_proba(X)[:, 1]
    y_pred = (y_proba >= threshold).astype(int)

    return {
        "F1": f1_score(y, y_pred),
        "Accuracy": accuracy_score(y, y_pred),
        "AUC": roc_auc_score(y, y_proba)
    }

def evaluate_models(models: dict, X_valid, y_valid, optimize_threshold=True):
    """
    å¯¹å¤šä¸ªæ¨¡å‹è¿›è¡Œè¯„ä¼°
    è‹¥ optimize_threshold=Trueï¼Œåˆ™ä¸ºæ¯ä¸ªæ¨¡å‹è‡ªåŠ¨æœç´¢æœ€ä¼˜ threshold
    """
    results = {}

    for name, model in models.items():
        if optimize_threshold:
            best_t, best_f1 = find_best_threshold(model, X_valid, y_valid)
            metrics = evaluate_model(model, X_valid, y_valid, threshold=best_t)
            metrics["BestThreshold"] = best_t
        else:
            metrics = evaluate_model(model, X_valid, y_valid)
            metrics["BestThreshold"] = 0.5

        results[name] = metrics

    print_metrics_table(results)
    return results